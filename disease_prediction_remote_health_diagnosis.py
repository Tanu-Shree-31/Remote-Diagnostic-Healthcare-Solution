# -*- coding: utf-8 -*-
"""Disease Prediction - Remote Health Diagnosis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1obLrWZp7jUv_mO5fjtjbO50KnZ_7aYEJ

##**1. Importing the necessary libraries and dataset**
"""

#Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn import tree
from joblib import dump

#Load training and test sets
train_data = pd.read_csv('/content/Training.csv')
test_data = pd.read_csv('/content/Testing.csv')

#visualising the train dataset - by printing the first 10 rows
train_data.head(10)

#visualising the test dataset - by printing the first 10 rows
test_data.head(10)

"""We see that the data is already encoded."""

train_data.columns[30:60]

"""#**2. Data Visualisation**"""

#lets see value counts and also visualize them
sns.set_theme(style="dark")
plt.figure(figsize = (10,25))
plt.xticks(rotation = 90)
sns.countplot(y="prognosis", data=train_data)
print(train_data["prognosis"].value_counts())

"""We see that the data is balanced."""

# linear relationships between some of features using correlation heatmap: for example which symptoms occur together?
df_corr = train_data.iloc[:, 10:40]
plt.figure(figsize = (30, 30))
sns.heatmap(df_corr.corr(), annot = True)
plt.show()

"""As we look at from correlation map, we can infer these:

- yellowish skin and abdominal pain have a high correlation coefficent which means these features usually seem together (maybe a liver problem)
- cough and breathlessness also have high correlation (it's usual because lung diseases give the same symptoms)
- restlessness and irregular sugar usually seem together

## Few points about correlation
* Values closer to zero means there is no linear trend between the two variables.
* The close to 1 the correlation is the more positively correlated they are; that is as one increases so does the other and the closer to 1 the stronger this relationship is. 
* A correlation closer to -1 is similar, but instead of both increasing one variable will decrease as the other increases.

#**3. Data Cleaning**
"""

#as we see there is an extra column present at last of train dataset, we exclude that
train_data.drop(['Unnamed: 133'], axis=1, inplace=True)

train_data.info(verbose=True)

"""We have 4920 entries of data (row) and 132 variables (columns) and 1 target variable with a string format"""

test_data.info(verbose=True)

"""All the columns are of integer data type, except the prognosis column - which tells us about the type of disease found.


"""

#Get prognosis values
train_data['prognosis'].unique()

train_data['prognosis'].value_counts()

test_data['prognosis'].value_counts()

#We find this out the mean values in the dataset.
#Features that have a mean value of 0 are never present when diagnosing 
train_data.describe()

test_data.describe()

"""We see that each column present posseses some mean value."""

train_data.isnull().sum()

"""We have no nulls in the data now we can proceed to building the ML model.

#**4. Model Building & Evaluation**
"""

#Shuffling the train and test data
final_train_data = train_data.sample(frac=1)
final_test_data = test_data.sample(frac=1)

X_train = final_train_data.iloc[:, :-1]
y_train = final_train_data.iloc[:, -1]

X_test = final_test_data.iloc[:, :-1]
y_test = final_test_data.iloc[:, -1]

"""### **(a) Decision Tree Model**"""

# Decision Tree

decision_tree = DecisionTreeClassifier()
decision_tree.fit(X_train, y_train)
Y_predDT = decision_tree.predict(X_test)
print("Train Accuracy: ",round(accuracy_score(y_train, decision_tree.predict(X_train))*100,2))
print("Test Accuracy: ",round(accuracy_score(y_test, Y_predDT) * 100 ,2))

"""### **(b) Random Forest Model**"""

classifier = RandomForestClassifier(bootstrap=True, max_features=None, n_jobs=-1, criterion='gini',n_estimators=10)
classifier.fit(X_train, y_train)
Y_predRF = classifier.predict(X_test)
classifier.score(X_train, y_train)
print("Train Accuracy: ",round(accuracy_score(y_train, classifier.predict(X_train))*100,2))
print("Test Accuracy: ",round(accuracy_score(y_test, Y_predRF)*100,2))

"""### **(c) Logistic Regression**"""

# Logistic Regression

logreg = LogisticRegression()
logreg.fit(X_train, y_train)
Y_predLR = logreg.predict(X_test)
print("Train Accuracy: ",round(accuracy_score(y_train, logreg.predict(X_train))*100,2))
print("Test Accuracy: ",round(accuracy_score(y_test, Y_predLR) * 100,2))

# Matrix showing the prediction made on the test set. For this particular set, the model has 100% accuracy
# We have shown the matrix comparison for Logistic regression
pd.crosstab(y_test, Y_predLR, rownames=['Actual Result'], colnames=['Predicted Result'])

# Tabular Representation of model accuracy of Training set
models_train = pd.DataFrame({
    'Model': ['Decision Tree', 'Random Forest', 'Logistic Regression'],
    'Score': [round(accuracy_score(y_train, decision_tree.predict(X_train))*100,2),
              round(accuracy_score(y_train, classifier.predict(X_train))*100,2),
              round(accuracy_score(y_train, logreg.predict(X_train))*100,2)]})
models_train.sort_values(by='Score', ascending=False)

# Tabular Representation of model accuracy of Testing set
models_test = pd.DataFrame({
    'Model': ['Decision Tree', 'Random Forest', 'Logistic Regression'],
    'Score': [round(accuracy_score(y_test, Y_predDT) * 100 ,2),
              round(accuracy_score(y_test, Y_predRF)*100,2),
              round(accuracy_score(y_test, Y_predLR) * 100,2)]})
models_test.sort_values(by='Score', ascending=False)

"""**Logistic Regression model has the most important performance metrics with 100% accuracy among**

Decision Tree with 97.62% accuracy and Random Forest with 97.62% accuracy.

Thus all prognosis are almost perfectly classified and predicted. The small difference between Decision Tree model and Random forest model's train and test datasets indicated that these models dont suffer from overfitting nor underfitting.

**In conclusion, the logistic model can be choosen as the best model to identify prognosis.**
"""

#Saving the Logistic regression weights for future use
logreg.feature_names = list(X_train.columns.values)
dump(logreg, 'logreg_weights.joblib')